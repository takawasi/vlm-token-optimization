# VLM Grid Focus Toolkit
**VLM画像認識の精度を上げる動的グリッドフォーカス手法**

> 全体把握→詳細フォーカスの2段階認識でCLI自動化を実現
> 人間の視覚認知と同じアプローチでVLMの認識精度を向上

[English README](./README_EN.md)

---

## 🎯 このツールキットで解決できること

- **VLMの画像認識精度向上**: 全体画像では見えない詳細をグリッドフォーカスで認識
- **CLI/自動化対応**: タイル番号指定でプログラマブルに画面領域を選択
- **差分検知**: 変化があった部分に自動でフォーカス

---

## 🧠 コンセプト: なぜグリッドフォーカスが必要か

### 問題: 全体画像では詳細が見えない

VLM（GPT-4V、Claude等）に1920×1080のフルスクリーンを1枚見せても:
- 小さいボタンの文字が読めない
- 細かいUI要素を認識できない
- 「どこに何があるか」は分かるが「詳細」は分からない

**人間も同じ。** 画面全体をぼんやり見ても細部は見えない。注目したい部分に目を向けて初めて詳細が見える。

### 解決: 2段階認識アプローチ

1. **全体把握**: フルスクリーン1枚で「どこに何があるか」を把握
2. **グリッド選択**: 詳細を見たい領域のタイル番号を選択
3. **詳細フォーカス**: 選択したタイル2-3枚で詳細を認識

```
全体1枚だけ → ぼんやり認識
全体1枚 + フォーカス2-3枚 → 詳細認識
```

---

## 📊 24分割グリッド

画面を6×4の24タイルに分割。タイル番号で領域を指定。

```
┌──────┬──────┬──────┬──────┬──────┬──────┐
│  1   │  2   │  3   │  4   │  5   │  6   │
├──────┼──────┼──────┼──────┼──────┼──────┤
│  7   │  8   │  9   │ 10   │ 11   │ 12   │
├──────┼──────┼──────┼──────┼──────┼──────┤
│ 13   │ 14   │ 15   │ 16   │ 17   │ 18   │
├──────┼──────┼──────┼──────┼──────┼──────┤
│ 19   │ 20   │ 21   │ 22   │ 23   │ 24   │
└──────┴──────┴──────┴──────┴──────┴──────┘
```

1タイル = 320×270px（1920×1080の場合）

---

## 🚀 構成ツール

### 1. Screen Capture 24Grid (`screen_capture_24grid.py`)
**目的**: 画面を24分割し、指定タイルのみを取得

**機能**:
- タイル番号での指定（左上=1、右下=24）
- 個別タイル or 複数タイル指定可能
- 全体把握用の縮小画像も出力可能

**使用例**:
```bash
# 全体把握 + タイル8,9（画面上部中央）を詳細取得
python screen_capture_24grid.py --overview --tiles 8,9
```

### 2. Screen Diff Detector (`screen_diff_detector.py`)
**目的**: 前回との差分を検知し、変化があったタイルを自動選択

**機能**:
- 前回スクリーンショットとの差分を24分割単位で検知
- 変化があったタイルのみを抽出
- 「どこが変わったか」を自動でフォーカス

**使用例**:
```bash
# 前回との差分を検知し、変化部分のみフォーカス
python screen_diff_detector.py --threshold 0.05
```

### 3. OCR Text Locator (`ocr_text_locator.py`)
**目的**: テキストの座標を取得し、該当タイルを特定

**機能**:
- OCRでテキスト検出
- テキストの画面上座標を取得
- 「送信ボタンはどのタイルか」を自動特定

**使用例**:
```bash
# "送信"ボタンがあるタイルを特定
python ocr_text_locator.py --text "送信"
```

---

## 💡 設計思想: 人間の視覚認知と同じ

### なぜ24分割なのか？

- **人間の視覚認知**: 一度に認知できる範囲は限定的
- **視線追跡研究**: 注目領域は全体の10-20%程度
- **Fの法則**: 左上→右→左下の視線移動パターン

VLMも同じ。全体を見せるより、「ここを見ろ」と領域を絞った方が精度が上がる。

### CLI/自動化向け設計

- **番号指定**: 「タイル8,9を見せろ」がコマンド1行
- **差分検知**: 「変わった部分だけ見せろ」が自動
- **パイプライン統合**: 他のCLIツールと組み合わせ可能

---

## 🛠️ 使用例（実践）

### ケース1: フォーム入力の詳細認識
```bash
# 1. 全体把握
python screen_capture_24grid.py --overview

# 2. VLM: 「フォームは画面中央（タイル13, 14）にあります」

# 3. 詳細フォーカス
python screen_capture_24grid.py --tiles 13,14

# 4. VLM: 「氏名欄のプレースホルダーは『山田太郎』です」
#    （全体画像だけでは読めなかった詳細が見える）
```

### ケース2: 変化部分への自動フォーカス
```bash
# 1. 差分検知
python screen_diff_detector.py --threshold 0.05

# 2. 出力: 「タイル14, 15に変化あり」

# 3. 変化部分だけフォーカス
python screen_capture_24grid.py --tiles 14,15
```

### ケース3: 特定テキストの詳細確認
```bash
# 1. "送信"ボタンの位置を検出
python ocr_text_locator.py --text "送信"

# 出力: タイル18に存在

# 2. 該当タイルを詳細確認
python screen_capture_24grid.py --tiles 18

# 3. VLM: 「送信ボタンは有効化されています（グレーアウトではない）」
```

---

## 📦 インストール

### 必須環境
- Python 3.8+
- macOS / Linux / Windows

### 依存パッケージ
```bash
pip install pillow numpy opencv-python pytesseract
```

### Tesseract OCRのインストール（OCR使用時）
```bash
# macOS
brew install tesseract

# Ubuntu/Debian
sudo apt-get install tesseract-ocr

# Windows
# https://github.com/UB-Mannheim/tesseract/wiki からインストール
```

---

## 📝 ライセンス

MIT License

---

## 🤝 コントリビューション

Issue、Pull Requestを歓迎します。

---

**開発**: TAKAWASI
**サイト**: https://takawasi-social.com/tech/vlm-token-optimization.html

---

*"全体を見渡し、詳細にフォーカスする。人間の目と同じように。"*
